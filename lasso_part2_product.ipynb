{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import copy\n",
    "\n",
    "# for sqrt \n",
    "import math\n",
    "from feature_selector import FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_y(x,y):\n",
    "    beta = cycliccoorddescent(x,y)[-1, :]\n",
    "    return np.dot(x,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true,predicted):\n",
    "    return math.sqrt(mse(np.log(true),np.log(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "test_id = list(np.arange(0, 2930,3))\n",
    "data = pd.read_csv('Ames_data.csv')\n",
    "train_id = list( \n",
    "    set(np.arange(0, 2930))-set(test_id))\n",
    "\n",
    "train = data.iloc[train_id,:]\n",
    "test = data.iloc[test_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract train-test target variable\n",
    "train_target = pd.DataFrame(train['Sale_Price'])\n",
    "test_target = pd.DataFrame(test['Sale_Price'])\n",
    "\n",
    "#drop the tatget variable from train-test\n",
    "train = train.drop(columns=['Sale_Price',\n",
    "                           'Street', \n",
    "                            'Utilities','Land_Slope', \n",
    "                            'Condition_2', 'Roof_Matl', 'Heating'\n",
    "                            , 'Pool_QC', 'Misc_Feature','Low_Qual_Fin_SF'\n",
    "                            , 'Three_season_porch','Pool_Area','Misc_Val'\n",
    "                            , 'Longitude','Latitude'])\n",
    "test = test.drop(columns=['Sale_Price',\n",
    "                           'Street', \n",
    "                            'Utilities','Land_Slope', \n",
    "                            'Condition_2', 'Roof_Matl', 'Heating'\n",
    "                            , 'Pool_QC', 'Misc_Feature','Low_Qual_Fin_SF'\n",
    "                            , 'Three_season_porch','Pool_Area','Misc_Val'\n",
    "                            , 'Longitude','Latitude'])\n",
    "\n",
    "#dummy coding process\n",
    "categorical_features = [col for col in train.columns if train[col].dtypes =='object']\n",
    "train = pd.get_dummies(train,columns = categorical_features)\n",
    "test = pd.get_dummies(test,columns = categorical_features)\n",
    "\n",
    "#make sure train-test has same shape and columns\n",
    "train_features,test_features = train.align(test,join = 'inner',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop highly correlated variables\n",
    "train_features_s = train_features.drop(columns = ['Garage_Yr_Blt'])\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "corr_matrix = train_features_s.corr()\n",
    "\n",
    "iters = range(len(corr_matrix.columns) - 1)\n",
    "drop_cols = []\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "for i in iters:\n",
    "    for j in range(i):\n",
    "        item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "        col = item.columns\n",
    "        row = item.index\n",
    "        val = abs(item.values)\n",
    "            \n",
    "            # If correlation exceeds the threshold\n",
    "        if val >= 0.8:\n",
    "                # Print the correlated features and the correlation value\n",
    "                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "            drop_cols.append(col.values[0])\n",
    "\n",
    "# Drop one of each pair of correlated columns\n",
    "drops = set(drop_cols)\n",
    "train_features = train_features.drop(columns = drops)\n",
    "\n",
    "#make sure train-test features has same shape and columns\n",
    "train_features,test_features = train_features.align(test_features,join = 'inner',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelector(data = train_features, labels = train_target)\n",
    "\n",
    "fs.identify_all(selection_params = {'missing_threshold': 0.8, 'correlation_threshold': 0.8, \n",
    "                                    'task': 'regression', 'eval_metric': 'l2', \n",
    "                                     'cumulative_importance': 0.95})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_importance_features = fs.ops['zero_importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.drop(columns=zero_importance_features)\n",
    "train_features,test_features =train_features.align(test_features,join = 'inner',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names\n",
    "# for to create zero-importance purpose\n",
    "# feature_names = list(train_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the end of pandas process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start numpy preprocessing process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute the data\n",
    "from sklearn.preprocessing import StandardScaler,Imputer\n",
    "\n",
    "im = Imputer(strategy = 'median')\n",
    "im.fit(train_features)\n",
    "train_features = im.fit_transform(train_features)\n",
    "test_features = im.fit_transform(test_features)\n",
    "\n",
    "print(np.where(~np.isfinite(train_features)))\n",
    "print(np.where(~np.isfinite(test_features)))\n",
    "\n",
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(train_features)\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_features = scaler.transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "train_features_pd = pd.DataFrame(train_features)\n",
    "test_features_pd = pd.DataFrame(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert y to one-dimensional array (vector)\n",
    "y = np.array(train_target).reshape((-1, ))\n",
    "y_test = np.array(test_target).reshape((-1, ))\n",
    "# normalize TRAIN Y-data and eshape\n",
    "scaler.fit(train_target)\n",
    "y = scaler.transform(train_target)\n",
    "y = np.array(y).reshape((-1, ))\n",
    "# start building coordinate descent\n",
    "lambda_optimal= 0.003\n",
    "# beta_star = beta_star\n",
    "\n",
    "def soft_threshold(a,lambda_optimal = 0.01567752):\n",
    "    \"\"\"\n",
    "    Solving l1-norm gradient problem\n",
    "    \"\"\"\n",
    "    if a < -lambda_optimal:\n",
    "        return a+lambda_optimal\n",
    "    elif a > lambda_optimal:\n",
    "        return a-lambda_optimal\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def min_beta_multivariate(x, y, beta, j):\n",
    "    \"\"\"\n",
    "    Solving partial minimization problem with respect to beta_j for any j = 1...d.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    selector = [i for i in range(x.shape[1]) if i != j]\n",
    "    norm_x_j = np.linalg.norm(x[:, j])\n",
    "    a = x[:, j].dot(y[:, np.newaxis] - x[:, selector].dot(beta[:, np.newaxis][selector, :]))\n",
    "    passin = lambda_optimal*n/2\n",
    "    res = soft_threshold(a, passin)\n",
    "    return res/(norm_x_j**2)\n",
    "\n",
    "\n",
    "def predict_cd(beta,x):\n",
    "    \"\"\"\n",
    "    Compute objective value with certain beta.\n",
    "    \"\"\"\n",
    "    return np.dot(x,beta)\n",
    "\n",
    "def cycliccoorddescent(x, y, beta_init,max_iter = 10):\n",
    "    \"\"\"\n",
    "    cycliccoorddescent that implements the cyclic coordinate descent algorithm. The cyclic\n",
    "    coordinate descent algorithm proceeds sequentially. \n",
    "    \"\"\"\n",
    "    beta = copy.deepcopy(beta_init)\n",
    "    beta_vals = beta\n",
    "    d = np.size(x, 1)\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        for j in range(d):\n",
    "            min_beta_j = min_beta_multivariate(x, y, beta, j)\n",
    "            beta[j] = min_beta_j\n",
    "            beta_vals = np.vstack((beta_vals, beta))\n",
    "        iteration += 1\n",
    "        if iteration % 100 == 0:\n",
    "            print('Coordinate descent iteration', iteration)\n",
    "    return beta_vals\n",
    "scaler.fit(train_target)\n",
    "\n",
    "# Apply transform t\n",
    "y = scaler.transform(train_target)\n",
    "y = np.array(y).reshape((-1, ))\n",
    "y.shape\n",
    "def predicted(x,y,beta_init):\n",
    "    beta = cycliccoorddescent(x,y,beta_init)[-1, :]\n",
    "    return predict_cd(beta,x)\n",
    "prediction = predicted(train_features,y,beta_init = np.zeros(np.size(train_features, 1)))\n",
    "rmse(scaler.inverse_transform(prediction),\n",
    "             np.array(train_target).reshape((-1, )))\n",
    "print(rmse(scaler.inverse_transform(predict_cd(cycliccoorddescent(train_features,y,beta_init = np.zeros(np.size(train_features, 1)))[-1, :],test_features)),\n",
    "             np.array(test_target).reshape((-1, ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = scalery.transform(test_target)\n",
    "#y = np.array(y).reshape((-1, ))\n",
    "#y_test = np.array(y_test).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start building coordinate descent "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
